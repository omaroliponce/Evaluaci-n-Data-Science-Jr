# -*- coding: utf-8 -*-
"""Evaluación Datasciencejr - Omar Ponce.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RmJt2fDB2atwiZn4mI3ZlERT_OhPIxBk
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import string as str
from sklearn.preprocessing import LabelEncoder

"""Variables
-Saldo Tres meses
-Saldo Seis meses
-Varación promedio de tres meses
-Varación promedio de seis meses
-Variación trimestral promedio
-Variación semestral promedio
-Contador de que sube y de que baja el saldo por cliente
-Edad
"""

df_clientes=pd.read_parquet('0clientes.parquet')
df_saldos=pd.read_parquet('0saldos.parquet')
df_transferencias=pd.read_parquet('0transferencias.parquet')

"""**Descubrimiento de las bases de datos**"""

df_clientes.head()

df_saldos.head()

df_transferencias.head()

df_transferencias["Anio_Mes"]=df_transferencias.apply(lambda row: f"{row.FechaEfectiva.year}_{row.FechaEfectiva.month}",axis=1)

df_transferencias.head()

df_transferencias.describe()

df_transferencias.groupby(["Anio_Mes","Contrato"]).agg({"ValorNeto":"sum"})

df_clientes.info()

print("Número de valores únicos en la columna 'NroDocum':", df_clientes['NroDocum'].nunique())

df_saldos.info()

df_transferencias.info()

"""Localizamos la coincidencia entre la tabla de clientes y la de saldos, por lo que utilizaremos un merge para unificar las tablas"""

df_clientes.head()

df_saldos.columns

df_saldos.groupby(["NroDocum"]).agg({"Contrato":"count"}).sort_values(by="Contrato",ascending=False)

df_saldos_agregados = df_saldos.groupby(["NroDocum"],as_index=False).agg({'SALDO_202101':"sum", 'SALDO_2021O2':"sum", 'SALDO_2021O3':"sum",
       'SALDO_2021O4':"sum", 'SALDO_2021O5':"sum", 'SALDO_2021O6':"sum", 'SALDO_2021O7':"sum",
       'SALDO_2021O8':"sum", 'SALDO_2021O9':"sum", 'SALDO_202110':"sum", 'SALDO_202111':"sum",
       'SALDO_202112':"sum", 'SALDO_202201':"sum", 'SALDO_202202':"sum", 'SALDO_202203':"sum",
       'SALDO_202204':"sum", 'SALDO_202205':"sum", 'SALDO_202206':"sum", 'SALDO_202207':"sum",
       'SALDO_202208':"sum", 'SALDO_202209':"sum", 'SALDO_202210':"sum",})

df_saldos_agregados

df_saldos_agregados.describe()

mes_actual= ["SALDO_202207"]
mes_anterior= ["SALDO_202206"]

trimestre_actual= ["SALDO_202205","SALDO_202206","SALDO_202207"]
trimestre_anterior= ["SALDO_202202","SALDO_202203","SALDO_202204"]

semestre_actual= ["SALDO_202202","SALDO_202203","SALDO_202204","SALDO_202205","SALDO_202206","SALDO_202207"]
semestre_anterior= ["SALDO_2021O8","SALDO_2021O9","SALDO_202110","SALDO_202111","SALDO_202112","SALDO_202201"]

meses_observacion=semestre_anterior+semestre_actual

df_variables=df_saldos_agregados[["NroDocum"]+meses_observacion].copy()

df_variables["promedio_trimestre_actual"]=df_variables[trimestre_actual].mean(axis=1)
df_variables["promedio_trimestre_anterior"]=df_variables[trimestre_anterior].mean(axis=1)
df_variables["promedio_semestre_actual"]=df_variables[semestre_actual].mean(axis=1)
df_variables["promedio_semestre_anterior"]=df_variables[semestre_anterior].mean(axis=1)

df_variables.head()

# prompt: saca la variación por fila de la columna promedio_trimestre_actual y promedio_trimestre_anterior

df_variables=df_variables.dropna()

df_variables['variacion_trimestre'] = (df_variables['promedio_trimestre_actual'] - df_variables['promedio_trimestre_anterior']) / df_variables['promedio_trimestre_anterior']
df_variables['variacion_semestre'] = (df_variables['promedio_semestre_actual'] - df_variables['promedio_semestre_anterior']) / df_variables['promedio_semestre_anterior']

df_variables.info()

def contadores(saldos,indicador):
  contador_sube=0
  contador_baja=0
  contador_estable=0
  saldo_auxiliar=saldos[0]
  for saldo in range(len(saldos)-1):
    saldo_actual=saldos[saldo+1]
    if saldo_actual==saldo_auxiliar:
      contador_estable+=1
    elif saldo_actual>saldo_auxiliar:
      contador_sube+=1
    else:
      contador_baja+=1
    saldo_auxiliar=saldo_actual

  return {"sube":contador_sube,"baja":contador_baja,"estable":contador_estable}[indicador]

df_variables["Incrementos"]=df_variables.apply(lambda row:contadores(row[meses_observacion],"sube"),axis=1)
df_variables["Decrementos"]=df_variables.apply(lambda row:contadores(row[meses_observacion],"baja"),axis=1)
df_variables["Estables"]=df_variables.apply(lambda row:contadores(row[meses_observacion],"estable"),axis=1)

df_variables.head()

df_clientes

df_clientes[['Ciudad', 'Region']] = df_clientes['CIUDAD'].str.split(',', expand=True)

df_clientes

regiones=df_clientes['Region'].value_counts().sort_values(ascending=False).head(30)
regiones

df_clientes['Region']

regiones = [
    'BOGOTA',
    'ANTIOQUIA',
    'VALLE DEL CAUCA',
    'CUNDINAMARCA',
    'ATLANTICO',
    'SANTANDER',
    'BOLIVAR',
    'CALDAS',
    'TOLIMA',
    'RISARALDA',
    'MAGDALENA',
    'BOYACA'
]
def region_mod(region,regiones):
  try:
    region=region.strip()
    if region in regiones:
      return region
    else:
      return "OTRA"
  except:
    return "OTRA"

"BOGOTA" in regiones

df_clientes["Region_Modificada"]=df_clientes.apply(lambda row: region_mod((row["Region"]),regiones), axis=1)

ejemplo=df_clientes.iloc[0,4]

df_clientes.head()

# prompt: QUIERO HACER UN MERGE ENTRE df_clientes y df_variables con la columna en comun NroDocum

df_clientes_variables = pd.merge(df_clientes[["NroDocum","FecNacim","Region_Modificada"]], df_variables, on='NroDocum')

df_clientes_variables.head()

from datetime import datetime
# Asegurar que 'FecNacim' sea de tipo datetime
df_clientes_variables['FecNacim'] = pd.to_datetime(df_clientes_variables['FecNacim'])

# Calcular la diferencia en años
hoy = datetime.today()
df_clientes_variables['Edad'] = (hoy - df_clientes_variables['FecNacim']).astype('<m8[Y]')

# Mostrar DataFrame con la nueva columna 'Edad'
df_clientes_variables.head()
df_modelo = df_clientes_variables.drop(["SALDO_2021O8",	"SALDO_2021O9", "SALDO_202110",
                                        "SALDO_202111", "SALDO_202112", "SALDO_202201",
                                        "SALDO_202202","SALDO_202203","SALDO_202204","SALDO_202205","SALDO_202206","FecNacim"],axis=1)

df_modelo.head()

df_modelo=df_modelo.dropna()

df_modelo.head()

df_modelo = pd.merge(df_modelo, df_saldos_agregados[['NroDocum', 'SALDO_202210']], on="NroDocum")

df_modelo

df_modelo=df_modelo[(df_modelo['SALDO_202207'] != 0) & (df_modelo['SALDO_202210'] != 0)]

def variacion(renglon):
  saldo_inicial=renglon.SALDO_202207
  saldo_final=renglon.SALDO_202210
  return saldo_final/saldo_inicial

def flag(renglon):
  if renglon.Variacion<=.70:
    return 1
  else:
    return 0

df_modelo['Variacion'] = df_modelo.apply(lambda row: variacion(row),axis=1)
df_modelo['FLAG'] = df_modelo.apply(lambda row: flag(row),axis=1)

df_modelo.head()

import pandas as pd

df_modelo = pd.get_dummies(df_modelo, columns=['Region_Modificada'])
df_modelo

df_modelo.columns

df_modelo.sort_values(by="variacion_trimestre",ascending=False)

df_modelo['variacion_trimestre'] = df_modelo['variacion_trimestre'].replace([float('inf'), -float('inf')], -100)
df_modelo['variacion_semestre'] = df_modelo['variacion_semestre'].replace([float('inf'), -float('inf')], -100)

df_modelo.groupby(["FLAG"]).agg({"FLAG":"count"})

from sklearn.model_selection import cross_val_score

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score,roc_auc_score

# Paso 1: Preparar los datos
X = df_modelo[['SALDO_202207', 'promedio_trimestre_actual',
       'promedio_trimestre_anterior', 'promedio_semestre_actual',
       'promedio_semestre_anterior', 'variacion_trimestre',
       'variacion_semestre', 'Incrementos', 'Decrementos', 'Estables', 'Edad', 'Region_Modificada_ANTIOQUIA',
       'Region_Modificada_ATLANTICO', 'Region_Modificada_BOGOTA',
       'Region_Modificada_BOLIVAR', 'Region_Modificada_BOYACA',
       'Region_Modificada_CALDAS', 'Region_Modificada_CUNDINAMARCA',
       'Region_Modificada_MAGDALENA', 'Region_Modificada_OTRA',
       'Region_Modificada_RISARALDA', 'Region_Modificada_SANTANDER',
       'Region_Modificada_TOLIMA', 'Region_Modificada_VALLE DEL CAUCA']]
y = df_modelo['FLAG']

import numpy as np

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

modelo = XGBClassifier(scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train))
modelo.fit(X_train, y_train)

probs_train = modelo.predict_proba(X_train)
probs_test = modelo.predict_proba(X_test)

auc_train = roc_auc_score(y_train, probs_train[:, 1], multi_class='ovr')
auc_test = roc_auc_score(y_test, probs_test[:, 1], multi_class='ovr')

print("AUC en conjunto de entrenamiento:", auc_train)
print("AUC en conjunto de prueba:", auc_test)

"""**Conslusiones**"""

from xgboost import plot_tree
import matplotlib.pyplot as plt

# Visualizar el primer árbol del modelo
fig, ax = plt.subplots(figsize=(20, 20))
plot_tree(modelo, num_trees=0, ax=ax)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

accuracy = accuracy_score(y_test, predicciones_test)

precision = precision_score(y_test, predicciones_test, average='weighted')

recall = recall_score(y_test, predicciones_test, average='weighted')

f1 = f1_score(y_test, predicciones_test, average='weighted')

matriz_confusion = confusion_matrix(y_test, predicciones_test)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Matriz de Confusión:")
print(matriz_confusion)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
sns.heatmap(matriz_confusion, annot=True, cmap='Greens', fmt='.2f', square=True,
            xticklabels=[f'Clase {i}' for i in range(matriz_confusion.shape[0])],
            yticklabels=[f'Clase {i}' for i in range(matriz_confusion.shape[0])])
plt.xlabel('Etiqueta Predicción')
plt.ylabel('Etiqueta Verdadera')
plt.title('Matriz de Confusión')
plt.show()